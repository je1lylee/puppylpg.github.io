---
layout: post
title: "HTTP123"
date: 2023-02-19 01:16:31 +0800
categories: http tcp udp
tags: http tcp udp
---

既然应用层基于传输层构建，那么http协议的底层就不必非得是tcp协议。能基于别的协议比如udp实现http吗？

> [透明多级分流系统-传输链路](https://icyfenix.cn/architect-perspective/general-architecture/diversion-system/transmission-optimization.html)

1. Table of Contents, ordered
{:toc}

# 现状
**一件事情看久了，就以为是理所当然的了**。人人都知道http是基于tcp的，这个世界上http+tcp在网络世界里是一种统治级的存在，那么**tcp真的适合http吗**？并不：
1. 从我们在网页上停留的时间可以知道，http传输对象的主要特征是：时间短、资源小、切换快；
2. 而tcp恰恰是一种与http的使用场景相悖的设计：
    1. **三次握手建立一个连接，大约需要百毫秒之后才能传输数据**；
    2. **慢启动，传输一段时间之后才开始加速**；

所以**tcp的设计理念和http的使用场景其实是有些相悖的：只有在长时间的尺度下，tcp建立连接的高昂成本才可以忽略不计，稳定性和可靠性的优势才能显现出来**。http基于tcp固然获得了稳定可靠的优势，但tcp并不完全适合http。

> 所谓“连接”，不过是个逻辑概念。client先告诉server我要给你发送数据，server同意，三次以后，才开始发，这样的话就认为往server的port上发的数据有人接收，是谓“连接”。这只是“二者之间仿佛有个连接”，但实际上，三次握手之后server依然可能挂掉，此时发过去的数据依然没人收。

## trick
既然tcp不完全适合http的使用场景，人们（尤其是和http关联最密切的前端）只好使用一些trick来基于tcp的特点优化http的性能——比如想尽办法复用连接，以减少tcp连接数，减少三次握手的次数：
1. 请求时将多张图片合并为一张sprite图：缺点是即使修改了一张小图，客户端缓存也会失效；
2. 合并多个异步请求：缺点是最慢的那个请求会影响所有请求的返回时间；

> trick之所以叫trick，是因为当用trick去解决一个问题时，会带来另一个问题，只能两害相权取其轻。否则它就不叫trick，而是一种标准的技术规范。**而这实际上意味着技术根基出了问题**。

## udp？
那http能基于udp吗？毕竟udp没有那么多连接开销。可以，但与此同时，http便失去了tcp带来的稳定可靠的优势，就要在应用层面自己解决这些问题了。实际上http3大概就是这么干的。

# HTTP1
http本身也考虑了连接开销的问题，所以http1.0就支持长连接（keep-alive），到了http1.1里长连接就成了默认行为。

长连接的本质：让客户端对同一个域名长期持有一个或多个不会用完即断开的tcp连接。

> 对同一个域名，现代浏览器一般只允许6个并发请求。

连接不关了，也带来了新的问题：
1. 怎么判断多个请求之间或者响应之间的分界？
2. 怎么判断哪个响应对应哪个请求？

## 多个连续请求/响应的分界
在不开启长连接的时候（一个请求+一个响应）：
1. 请求通过header里的`Content-Length`指定一个请求的结束；
2. **响应通过header里的`Content-Length`或者直接关闭tcp连接代表一个响应的结束**；

在[rfc1945 7.2](https://www.ietf.org/rfc/rfc1945)中规定，请求必须有length：
> HTTP/1.0 requests containing an
   entity body must include a valid Content-Length header field.

在7.2.2中规定，响应可以用length，也可以靠直接关闭连接表明结束：
> When an Entity-Body is included with a message, the length of that
   body may be determined in one of two ways. If a Content-Length header
   field is present, its value in bytes represents the length of the
   Entity-Body. Otherwise, the body length is determined by the closing
   of the connection by the server.

同时特意强调了，**request不能通过关闭流来表明自己结束了**，不然server会一脸懵逼：老哥我怎么把响应给你？
> Closing the connection cannot be used to indicate the end of a
   request body, since it leaves no possibility for the server to send
   back a response.

所以根据规定可以看出，通过`Content-Length`可以解决这一问题。但有些场景并不能提前知道content的length到底是多少，比如**即时压缩（on-the-fly compression）**：资源并没有提前压缩好放在server上，而是server在收到header为`Accept-Encoding: gzip`的request后，当场在内存中对资源进行压缩，“边压缩边发送”响应给client（`Content-Encoding: gzip`）。这样的话，server也不知道最终压缩完的content会有多大。**所以长连接和即时压缩在http1.0里是冲突的，只能开启一个**！

> 更早的时候，server性能比较差，为了同时支持请求压缩和不压缩资源的request，必须预压缩一份gz文件提前放到服务器上，所以又叫静态预压缩（static precompression）。那个时候length是可以提前知道的。

http1.1引入了**分块传输编码（chunked transfer encoding）**来解决这个问题：在header里声明`Transfer-Encoding: chunked`，之后就可以把body“一块一块”发给对方。块与块之间以本块内容的长度开始（十六进制），以空行结束。**最后一块的长度恒为0，代表没有了**。

[Wikipedia举的例子](https://en.wikipedia.org/wiki/Chunked_transfer_encoding)：
```
4\r\n        (bytes to send)
Wiki\r\n     (data)
6\r\n        (bytes to send)
pedia \r\n   (data)
E\r\n        (bytes to send)
in \r\n
\r\n
chunks.\r\n  (data)
0\r\n        (final byte - 0)
\r\n         (end message)
```
每一块分别是：
1. Wiki
2. pedia空格
3. in空格空行空行chunks.
4. 一个表明了长度为0的块

合起来内容就是：
```
Wikipedia in 

chunks.
```

所以**http1.1通过分块传输解决了即时压缩和长连接并存的问题**。

## 请求和响应的对应关系
http1.0虽然可以开启长连接，但是请求和响应必须一来一回，再一来一回，太慢了。http1.1引入了http pipelining，可以在连接上发一堆请求，再收一堆请求。请求与请求、响应与响应之间的分隔问题虽然解决了，该怎么判断哪个响应对应哪个请求呢？方案也很简单，第一个返回的响应就对应第一个请求。client维护一个FIFO队列，记录下当前在途的请求。server也维护一个FIFO队列。第一个返回的response一定对应队首的request。之后client第一个request出队，继续等下一个。

这么做最典型的问题就是**队首阻塞（head of line blocking）**：如果第一个请求不返回，后面的请求一定不会返回。但实际上后面的请求和之前的请求消耗的服务器资源未必相同，也许先被并发处理完了。**但是这种方案严格要求返回顺序，所以第一个不返回，后面的都不能返回**。

![HTTP_pipelining](/assets/screenshots/http/HTTP_pipelining.png)

http2解决了该问题。

# HTTP2
**队首阻塞的根本原因是在http1中，请求是http传输的最小单位。在http2中，最小单位变成了帧（frame），一个frame可以用来表示各种数据**，比如：
- headers
- body
- 控制标识
    + 打开流
    + 关闭流

**流（stream）和连接（connection）一样，都只是逻辑上的概念。每个帧都带一个流id，来标记这些帧属于同一个数据流。因此，从逻辑上可以认为一个http连接上存在多个stream**。client可以以任意顺序收发帧，然后按照每个帧的流id重组出不同的request或response。因此说，http2能够**多路复用（multiplexing）**。

**有了多路复用，http2就可以只对每个域名维持一个tcp连接，并以任意顺序传输request/response的数据**。因此，client就不需要通过并发建立连接的方式来实现并发请求：
1. server端tcp连接数变少，压力变小；
2. client端无需刻意压缩合并多个请求，不再需要trick。浏览器也不用限制一个域名最多并发开6个连接；

> 纠正技术本身的缺陷之后，便不再需要trick。

http2通过多个stream实现了多路复用，加快了并发处理的速度，因此选择只和每个域名维持一个长连接，抛弃了http1时靠创建多个长连接带来的并发能力。**绝大部分情况下，http2一个长连接加上本身的多路复用能力，传输速度可以超过http1的多个长连接。有一个情况除外：tcp包错误后的重传机制。**

一个tcp包出现错误导致的tcp重传会丢掉那个包之后所有接收到的数据，相当于毁掉了从那个包起这个连接上的所有数据。**无论对于http1还是对于http2，代价是一样大的。不过在http2的场景下，代价“显得”更大了：即使后续这些数据和错误的包不属于同一个stream，也要重传**。在http1里（可认为只存在一个stream），丢了一个包就重传后面所有数据似乎是理所当然的，毕竟后面所有的数据都属于这一个stream，错一个包都没法组成完整数据。但是在http2里，错一个包理论上并不影响别的stream数据的完整性，但是也要被迫再重传一遍数据，看起来似乎就有些不合理了。这个问题在http3里得到了解决。

**因此和http1相比，http2更适合传输多个小资源**：传输小文件会让该stream存在的时间变短，受到其他stream丢包重传干扰的概率也更小。**所以传输多个大文件的话，http2大概率比http1慢**：
1. http1能开多个连接，并发下载。而http2只有一个连接；
2. 最主要的原因：一次tcp重传会导致所有的stream的数据都重传，不属于这个stream的其他stream也都要重传，相当于白搞多路复用了；

> 在大多数情况下，TCP协议接到数据包丢失或损坏通知之前，可能已经收到了大量的正确数据，但是在纠正错误之前，其他的正常请求都会等待甚至被重发，这也是HTTP/2未能解决传输大文件慢的根本原因。

所以在[这个“HTTP/2 is the future of the Web, and it is here!”](https://http2.akamai.com/demo)的例子里，http2比http1快很多，主要原因就是请求的是多个小文件，多路复用效果明显。

# HTTP3
http2之所以更快，是因为多路复用更适合http协议的使用场景了：请求多个短小资源。而tcp失败重传技术则极大地干扰了http2的多路复用能力。如何避免？那就失败不重传！udp：正是在下！

于是Google设计了基于udp的**QUIC（quick udp internet connection），快速udp网络连接**，提交给了IETF，最终IETF推出了**http3，http over quic**。

> google有能力推出，因为它在client端有chrome和android，在市场上有巨大的份额，可以让自己的server（youtube.com、google.com）和client端同时加入对http3的支持。

既然底层是udp，传输层不负责可靠传输，那就只能由应用层来做这件事了。**虽然看起来要做的事情变多了，但是别忘了正是tcp的可靠传输机制——失败重传，导致http2的多路复用效率不高。现在就是要让应用层的http3自己来控制失败重传，把控制权掌握在自己手中，一个stream发生错误，不影响其他stream。**

另外http3针对当前移动设备盛行的局面做了一些专门的支持，比如网络切换：如果是tcp协议，所有连接都会超时断开，之后再重建连接。**quic则用连接标识符标记连接（而不是ip地址），当网络环境切换导致连接断开后，client把连接标识符重新发给server即可使用新的ip重用已有连接**。

# 感想
http over udp，不知道当初学http的时候有没有想过这个问题。似乎我从不曾想过这个问题，大概是学艺不精，在看到http+tcp独领风骚的时候，甚至丧失了质疑的能力。

再者，2015年google将quic提交ietf的时候（同时http2正式推出），我正忙于学习计算机网络，那时候完全没注意到这些东西。2018年http3的概念正式推出的时候，也是刚毕业忙于适应新工作，也没有注意到这些东西。想来想去，只有强大了才能有所感触，只有闲下来了才能有所思考。好在http3在2022年才正式推出，现在了解还不算晚。顺便再立个flag，等着迎接http4吧，到时候不会再错过了。

> http这个二十年没动过的东西，怎么一到我这儿就开始疯狂迭代了……Java也是……嫌我学的快？

最后继续感慨一下[《凤凰架构》](https://icyfenix.cn/)这本书太强了，讲起东西来高屋建瓴，来龙去脉历史渊源介绍的清清楚楚，学起来非常自然。而之前http各个版本碎片化的知识快把我看懵逼了:(

> 书籍是人类进步的阶梯，哪怕自己没有思考的能力，也可以围观一下别人思考的结果。看多了，变强了，知识底蕴丰厚了，自己自然也能思考起来了。

